{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a64916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # to work with csv files\n",
    "\n",
  
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
   
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "print('sklearn stopwords :',len(_stop_words.ENGLISH_STOP_WORDS))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "print('NLTK Stopwords :',len(stopwords.words('english')))\n",
    "\n",
  
    "import string\n",
    "import re\n",
    "\n",
    
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
   
    "from sklearn.metrics import accuracy_score\n",
    "\n",
 
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
   
    "from time import time\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1903ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/us-economic-news-articles/US-Economic-News.csv\" , encoding = \"ISO-8859-1\" )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"relevance\"].value_counts()/df.shape[0] # Class distribution in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e081b1d",
   "metadata": {},
   "outputs": [],
   "source": [
  
    "df1 = df[df.relevance != \"not sure\"] # removing the data where we don't want relevance=\"not sure\".\n",
    "print(df1.shape)\n",
    "df1['relevance'] = df1.relevance.map({'yes':1, 'no':0}) # relevant is 1, not-relevant is 0. \n",
    "df2 = df1[[\"text\",\"relevance\"]] # Let us take only the two columns we need.\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b990be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = _stop_words.ENGLISH_STOP_WORDS\n",
    "\n",
    "def clean(doc): # doc is a string of text\n",
    "    doc = doc.replace(\"</br>\", \" \") # This text contains a lot of <br/> tags.\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    doc = \" \".join([token for token in doc.split() if token not in Stopwords])\n",
    "    # remove punctuation and numbers\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
  
    "from sklearn.model_selection import train_test_split\n",
    "\n",

    "X = df2.text # the column text contains textual data to extract features from\n",
    "y = df2.relevance # this is the column we are learning to predict. \n",
    "print(X.shape, y.shape)\n",
 
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c7c31",
   "metadata": {},
   "outputs": [],
   "source": [

    "vect = CountVectorizer(preprocessor=clean) # instantiate a vectoriezer\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)# use it to extract features from training data\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_train_dtm.shape, X_test_dtm.shape)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier and predict for test data\n",
    "nb = MultinomialNB() # instantiate a Multinomial Naive Bayes model\n",
    "%time nb.fit(X_train_dtm, y_train) # train the model(timing it with an IPython \"magic command\")\n",
    "y_pred_class = nb.predict(X_test_dtm) # make class predictions for X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the classifier using various measures\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=15)\n",
    "    plt.xlabel('Predicted label',fontsize=15)\n",
    "    \n",
    "    \n",
    "# Print accuracy:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with all features')\n",
    "\n",
    "# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n",
    "# Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "print(\"ROC_AOC_Score: \", roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2003c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(preprocessor=clean, max_features=5000) # Step-1\n",
    "X_train_dtm = vect.fit_transform(X_train) # combined step 2 and 3\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB() # instantiate a Multinomial Naive Bayes model\n",
    "%time nb.fit(X_train_dtm, y_train) # train the model(timing it with an IPython \"magic command\")\n",
    "y_pred_class = nb.predict(X_test_dtm) # make class predictions for X_test_dtm\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
    "# print the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with max 5000 features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b06bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # import\n",
    "\n",
    "logreg = LogisticRegression(class_weight=\"balanced\") # instantiate a logistic regression model\n",
    "logreg.fit(X_train_dtm, y_train) # fit the model with training data\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate evaluation measures:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "print(\"AUC: \", roc_auc_score(y_test, y_pred_prob))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce59e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vect = CountVectorizer(preprocessor=clean, max_features=1000) # Step-1\n",
    "X_train_dtm = vect.fit_transform(X_train) # combined step 2 and 3\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "classifier = LinearSVC(class_weight='balanced') # instantiate a logistic regression model\n",
    "classifier.fit(X_train_dtm, y_train) # fit the model with training data\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_class = classifier.predict(X_test_dtm)\n",
    "\n",
    "# calculate evaluation measures:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "print(\"AUC: \", roc_auc_score(y_test, y_pred_prob))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lime to interpret predictions\n",
    "\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    CountVectorizer(preprocessor=clean, max_features=5000),\n",
    "    SVC(class_weight='balanced', degree = 2,  kernel = 'sigmoid', probability= True)\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train) # train the model(timing it with an IPython \"magic command\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting values\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# calculating accuracy score\n",
    "accuracy_score = accuracy_score(y_test,y_pred)\n",
    "print('accuracy score : ',accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca38be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_pred,y_test, target_names =['not relevant','relevant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0dde8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
